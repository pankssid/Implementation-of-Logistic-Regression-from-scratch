{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2) (500, 2)\n"
     ]
    }
   ],
   "source": [
    "mean_01 = np.array([1.0, 0.5])\n",
    "mean_02 = np.array([4.0, 5.2])\n",
    "\n",
    "cov_01 = np.array([[1.0,0.1], [0.1, 1.0]])\n",
    "cov_02 = np.array([[1.0,0.1], [0.1, 1.2]])\n",
    "\n",
    "dist_01 = np.random.multivariate_normal(mean_01, cov_01, 500)\n",
    "dist_02 = np.random.multivariate_normal(mean_02, cov_02, 500)\n",
    "\n",
    "print (dist_01.shape, dist_02.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "rows = dist_01.shape[0] + dist_02.shape[0]\n",
    "cols = dist_01.shape[1] + 1\n",
    "\n",
    "data = np.zeros((rows, cols))\n",
    "print (data.shape)\n",
    "\n",
    "data[:dist_01.shape[0], :2] = dist_01\n",
    "data[dist_01.shape[0]:, :2] = dist_02\n",
    "data[dist_01.shape[0]:, -1] += 1.0\n",
    "\n",
    "print (data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.62563501  3.31001405  1.        ]\n",
      " [ 2.96980505  6.53388177  1.        ]\n",
      " [ 2.00102522  1.85223724  0.        ]\n",
      " [ 1.09438133  1.37388499  0.        ]\n",
      " [ 1.8747474   1.95680807  0.        ]\n",
      " [ 0.42902008  1.83824416  0.        ]\n",
      " [-0.40265047 -0.68352751  0.        ]\n",
      " [-0.80760982 -0.17806399  0.        ]\n",
      " [ 1.97968805  0.27022094  0.        ]\n",
      " [ 0.69492879  1.03466787  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "print (data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(650, 2) (650,)\n",
      "(350, 2) (350,)\n"
     ]
    }
   ],
   "source": [
    "split = int(0.65*data.shape[0])\n",
    "\n",
    "X_train = data[:split, :2]\n",
    "X_test = data[split:, :2]\n",
    "\n",
    "y_train = data[:split, -1]\n",
    "y_test = data[split:, -1]\n",
    "\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1+np.exp(-1*z))\n",
    "\n",
    "def hypothesis(x, w, b):\n",
    "    h = (x*w).sum() + b\n",
    "    return sigmoid(h)\n",
    "\n",
    "# Binary CrossEntropy   #BCE ERROR\n",
    "def get_error(x, w,y_true, b):\n",
    "    err = 0.0\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    for ix in range(m):\n",
    "        if y_true[ix] == 0:\n",
    "            err += (np.log(1- hypothesis(x[ix], w, b)))\n",
    "        else:\n",
    "            err += (np.log(hypothesis(x[ix], w, b)))\n",
    "    \n",
    "    err = err/m\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(x, w, y_true, b):\n",
    "    grad_w = np.zeros(w.shape[0])\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    for ix in range(m):\n",
    "        grad_w += (y_true[ix] - hypothesis(x[ix], w, b))*(-1*x[ix])\n",
    "        grad_b += (y_true[ix] - hypothesis(x[ix], w, b))*(-1)\n",
    "        \n",
    "    grad_w = grad_w/m\n",
    "    grad_b = grad_b/m\n",
    "    \n",
    "    return [grad_w, grad_b]\n",
    "\n",
    "def get_stochastic_grad(x_sample,w,y_true,b):\n",
    "    grad_w=0.0\n",
    "    grad_b=0.0\n",
    "    \n",
    "    grad_w=(y_true - hypothesis(x_sample,w,b))*(-1*x_sample)\n",
    "    grad_b=(y_true - hypothesis(x_sample,w,b))*(-1)\n",
    "    \n",
    "    return [grad_w,grad_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(x, w, y_true, b, learning_rate=0.01):\n",
    "    error = get_error(x, w, y_true, b)\n",
    "    [grad_w, grad_b] = get_gradients(x, w,y_true, b)\n",
    "    \n",
    "    w = w - learning_rate*grad_w\n",
    "    b = b - learning_rate*grad_b\n",
    "    \n",
    "    #return w, b\n",
    "    return error, w, b\n",
    "def stochastic_optimizer(x,w,y_true,b,learning_rate=0.1):\n",
    "    error=get_error(x,w,y_true,b)\n",
    "    \n",
    "    for ix in range(x.shape[0]):\n",
    "        [grad_w,grad_b]=get_stochastic_grad(x[ix],w,y_true[ix],b)\n",
    "    \n",
    "        w = w  - learning_rate*grad_w\n",
    "        b = b - learning_rate*grad_b\n",
    "    \n",
    "    return error,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_sample, w, b):\n",
    "    conf = hypothesis(x_sample, w, b)\n",
    "    if conf>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_accuracy(x_test, y_test, w, b):\n",
    "    y_pred = []\n",
    "    for ix in range(x_test.shape[0]):\n",
    "        y_pred.append(predict(x_test[ix], w, b))\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    return float((y_pred==y_test)).sum()/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "\n",
    "W = np.array([0.5, 0.5])\n",
    "b = 4.21\n",
    "n_iters = 150\n",
    "for ix in range(n_iters):\n",
    "    ## Complete the interpretation method here\n",
    "    ## 1. Initialise w, b\n",
    "    ## 2. Run Optimizer in loss\n",
    "    ## 3. Log accuracy and loss\n",
    "    ## 4. Plot the curves\n",
    "    err, W, b = optimizer(X_train, W, y_train, b, learning_rate=0.01)\n",
    "    loss.append(err)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.15174196 2.42170389]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF7pJREFUeJzt3X2sXPV95/H3d+742QYMNg/GXGwSp4mTpSG9JUFlt81CU0Bp2FSNBO2qtM3KWqnRplWlCtZSpd2/WmW1TVZhk1pJt1GWbZLNlgUFGgIku1F2G4LJ8mwg5inYJoB5MHC59r0z890/5tx7x5d5uPZceyZn3i9xNXPO+c35/eaYOZ/5nd85cyIzkSSNnsqgGyBJGgwDQJJGlAEgSSPKAJCkEWUASNKIMgAkaUQZAJI0ogwASRpRBoAkjajqoBvQzYYNG3LLli2DboYk/dy47777DmbmxsWUHeoA2LJlC7t37x50MyTp50ZEPLvYsh4CkqQRZQBI0ogyACRpRC1JAETEFRHxeETsjYjr2yxfERFfL5bfExFblqJeSdLx6zsAImIMuBG4EtgOXBsR2xcU+yTwama+E/gr4C/7rVeS1J+l6AFcDOzNzKcycxr4GnD1gjJXA18pnn8TuCwiYgnqliQdp6UIgHOB51qm9xXz2pbJzBpwCDhjCeqWJB2nobsOICJ2ADsAxsfHB9waqbfMpJHzj41MsnhsZJJANph/PvcISVL8Nzedc9PN53RaVsznqPkt5VqeH/M6jqWNzZcvqHeRbSzKva19s21u2cZz03PLWl83/x47LaN1HS3vc+G82emFt8ud2xa0a9/bl82/LhdVvrWdq1dU+de/+g5OtKUIgP3AeS3Tm4t57crsi4gqcCrwcruVZeYuYBfAxMSENyw+ARqNZLreoNZIZmoNZhoNavVkpt5gpnis1YsyRbnpemuZBvVGUm80d3D1BtQbxbxsrr82t6zlL5NGy/Oj11G85qh1NKgXO87Wco2WHe78jrZlR0zSaHTYEbdMNxrzO6mF62h97VGvSWDhtLTENq5b8XMTAPcC2yJiK80d/TXA7ywocytwHfCPwG8D303vRn+URiOZnK4xeaTOm0dqvHmkxmTx+ObhGpPTNaam6xyeaXCk1nw8XKtzpOWxOb/OkVrjqMfp2vyOfabeGMhOqxIwVgkqEYxVWv4iqFSC6oJllYBqpUKlEoxVYCxi7vWVShDAWKVCpQKVCCKarwmOnm6WhyCI2emYL9Oc9/bXxILH2fm0WUez3mJe5ejXtNZbvHyu3gCIKObNl22dpvU1s/NbyrJw2YJ1wIJ6F6yj7fppbd/CdS5y/Ue1r2Udx9LGZgvm1jOruZ5iGUfX0Vp+7mVdls3Wd/Sy+ULHUr61ne2Wta5jdp2t/4aD0HcAZGYtIj4F3AGMAX+TmY9ExL8HdmfmrcCXga9GxF7gFZohUWpT03UOHJri+dcO8/LkEV6dnOaVt2aKx+nm4+Q0r741Xezg64ted7USrFw2xopqpfm4rMKK6hgrl1VYWR1jzZoqK6vN+SurYyyvVlg2VmFZNVhWqVAdi+Z08Vgdq7B8LKhWKiyrVlhWCaoty5tlguXFY7VSoTq7o164845gbGx2xz6/43bMXxo+McxfxCcmJnKYfwvo1clpnnjhDZ548U2efPFNDrw2xYFDUxx47TCvTE63fc1pq5dx+urlrF+znNPXLGf96mWsW7mMNSuqrFtRZc2KKmtWjLF2RZW1xfTs4+rlzZ1+dczr9yS1FxH3ZebEYsoO3SDwsJqpN3h4/yHufeYVfvT0qzyw7zVeeuPI3PLVy8fYvH4Vm05bxYWbT+Pc01ax6bSVnH3KKjauW8761cs5ddUyd96ShoYB0MUbh2e489EXuP2hn/F/9h5kaqZ5mGbrhjX8s20beffZ69h21lreddY6zjl1pYc5JP1cMQDaePrgJF/+wVPc/OP9TE7XOefUlXxiYjMf3HoGv7x1PWeuWznoJkpS3wyAFq9MTvPZu57gv93zUyqV4Dcv3MTvfHCci847jUrFb/eSysUAKNz7zCv80U0/5uXJaa69+Dw+fdm72LhuxaCbJUknjAEA3HTPs/z5LY9w3vpV/O0fXMr2TacMukmSdMKNfADc9uDz7Lz5YT78Cxv53LUXccrKZYNukiSdFCMdALufeYU/+cb9/NL56/nCv/wlVi4bG3STJOmkGdmT0o/U6vzx1+9n06kr+dLvTbjzlzRyRrYH8NV/fJZ9r07xXz/5QdavWT7o5kjSSTeSPYBDUzN8/nt7+afbNnDptg2Dbo4kDcRIBsAX//eTvPbWDNdf+e5BN0WSBmbkAqDeSL5x73Nc8d6zee+mUwfdHEkamJELgPufe5WXJ6e56sJzBt0USRqokQuAu/a8SLUS/Oq7Ng66KZI0UCMXAHfveYFf3nI6p67ygi9Jo22kAuCnL7/FEy+8yeXbzxp0UyRp4EYqAO7a8wIAl7/nzAG3RJIGb6QC4O7HXmDbmWs5/4w1g26KJA3cSAXAIwdeZ2LL6YNuhiQNhZEJgFcnp3ntrRnesdFv/5IEIxQATx2cBOACA0CSgFEKgJfeBGDrhrUDbokkDYeRCYCnD05SrQSb168adFMkaSiMVACMn7GaZWMj85YlqauR2Rs+fXCSCzZ4/F+SZo1EADQaydMHJ9lqAEjSnJEIgAOHpjhSazgALEktRiIAnvYUUEl6m9EKAA8BSdKckQiAp16aZM3yMTauWzHopkjS0OgrACLi9Ii4MyJ+Ujyu71CuHhH3F3+39lPn8Xjq4CQXbFxLRJzsqiVpaPXbA7geuDsztwF3F9PtTGXm+4u/j/VZ5zF79uVJzj9j9cmuVpKGWr8BcDXwleL5V4B/0ef6TohXJ6fZsNbDP5LUqt8AOCszny+e/wzodKutlRGxOyJ+GBEnNSQajeSNIzVOWVk9mdVK0tDruVeMiLuAs9ss2tk6kZkZEdlhNedn5v6IuAD4bkQ8lJlPdqhvB7ADYHx8vFfzenpzukYmnOI9gCXpKD0DIDMv77QsIl6IiHMy8/mIOAd4scM69hePT0XE/wIuAtoGQGbuAnYBTExMdAqURXt9agaAU1YaAJLUqt9DQLcC1xXPrwNuWVggItZHxIri+QbgV4BH+6x30V6fqgFwyioPAUlSq34D4C+AX4+InwCXF9NExEREfKko8x5gd0Q8AHwP+IvMPHkBcLjoAXgISJKO0tfX4sx8GbiszfzdwL8qnv9f4J/0U08/PAQkSe2V/krgQ0UAnGoPQJKOUvoAeP1wMQZgD0CSjlL+ACh6AGu9DkCSjlL+ADg8w7oVVcYq/g6QJLUqfwBM1TwDSJLaKH8AHJ4xACSpjfIHwNSMvwMkSW2UPgAOTdkDkKR2Sh8AbxyueQqoJLVR+gB4fWrG3wGSpDZKHQD1uXsB2AOQpIVKHQBvzl4F7BiAJL1NqQNg7pdAPQtIkt6m1AHgD8FJUmelDoC5n4I2ACTpbcodAIe9F4AkdVLuAPB2kJLUUbkDwNtBSlJH5Q6AqRkiYO1yewCStFC5A+BwjXUrqlS8F4AkvU2pA+DQ1AynrvbwjyS1U+oAaP4UtAEgSe2UOwAOGwCS1Em5A2Cq5imgktRBuQPAHoAkdVTqAJiaqbNy2digmyFJQ6nUAVCvJ9UxTwGVpHZKHQC1RrJsrNRvUZKOW6n3jvVGMuZFYJLUVqkDoNZoUDUAJKmt0gZAo5E0EnsAktRBXwEQEZ+IiEciohERE13KXRERj0fE3oi4vp86F6ueCWAPQJI66LcH8DDwW8D3OxWIiDHgRuBKYDtwbURs77PenuqNZgCMVUrbyZGkvvR1mWxm7gGI6Pot+2Jgb2Y+VZT9GnA18Gg/dfdSa9gDkKRuTsbX43OB51qm9xXzTqh6fbYHYABIUjs9ewARcRdwdptFOzPzlqVuUETsAHYAjI+PH/d6ao0GgBeCSVIHPQMgMy/vs479wHkt05uLeZ3q2wXsApiYmMjjrXR+DMAAkKR2TsYhoHuBbRGxNSKWA9cAt57oSh0DkKTu+j0N9OMRsQ+4BLgtIu4o5m+KiNsBMrMGfAq4A9gDfCMzH+mv2b15FpAkddfvWUA3Aze3mX8AuKpl+nbg9n7qOlYz9WIMwB6AJLVV2q/HjgFIUnelDQDHACSpu9IGgD0ASequtAEw1wPwOgBJaqu0AVCfvRDMs4Akqa3S7h1rdccAJKmb0gaAYwCS1F1pA8AxAEnqrrQB4JXAktRdafeOXgcgSd2VNgBmzwJyDECS2ittANgDkKTuShsAngUkSd2VNgDmrwMo7VuUpL6Udu841wPwNFBJaqu0AeAYgCR1V9oA8CwgSequtAEw428BSVJXpQ0AzwKSpO5KGwDzYwClfYuS1JfS7h0dA5Ck7kobAJ4FJEndlTYA6o2kElAxACSprdIGQK2RHv+XpC5Ku4esN9Lj/5LURWkDoFZPj/9LUhelDYB6o+HvAElSF6UNgOYYgAEgSZ2UNgAcA5Ck7kobAJ4FJEndlXYPaQ9AkrrrKwAi4hMR8UhENCJioku5ZyLioYi4PyJ291PnYjkGIEndVft8/cPAbwF/vYiyH87Mg33Wt2j1RsMegCR10VcAZOYegIjh29HW6h4CkqRuTtYYQALfiYj7ImLHyaiw3kiqXgcgSR317AFExF3A2W0W7czMWxZZz6WZuT8izgTujIjHMvP7HerbAewAGB8fX+Tq326mkYx5FpAkddQzADLz8n4rycz9xeOLEXEzcDHQNgAycxewC2BiYiKPt856o+EgsCR1ccK/IkfEmohYN/sc+AjNweMTyjEASequ39NAPx4R+4BLgNsi4o5i/qaIuL0odhbwg4h4APgRcFtmfrufehej7mmgktRVv2cB3Qzc3Gb+AeCq4vlTwC/2U8/xqDWSVQaAJHVU2lHSeiNZNlbatydJfSvtHrLmT0FIUlelDQDPApKk7kobAPYAJKm70gaAZwFJUnelDYDmdQClfXuS1LfS7iHtAUhSd6UNgFojvSm8JHVR2gDwLCBJ6q60AeBZQJLUXWkDwDEASequtAFQ834AktRVafeQ9gAkqbtSBkBmUncMQJK6KmUA1BrNG4nZA5CkzkoZAPUiALwOQJI6K2UA2AOQpN5KGQD1+mwAlPLtSdKSKOUestZoAFD1EJAkdVTKAJgbA/AQkCR1VMoAcAxAknorZQDM9wBK+fYkaUmUcg9pD0CSeitlANSLQWDHACSps1IGgD0ASeqtnAFQ9ywgSeqllAEwOwjsdQCS1FkpA6DmWUCS1FMp95B1xwAkqadSBkDNs4AkqadSBoA9AEnqra8AiIjPRMRjEfFgRNwcEad1KHdFRDweEXsj4vp+6lwMzwKSpN767QHcCbwvMy8EngBuWFggIsaAG4Erge3AtRGxvc96u5q/DqCUHRxJWhJ97SEz8zuZWSsmfwhsblPsYmBvZj6VmdPA14Cr+6m3F68ElqTelvIr8h8C/9Bm/rnAcy3T+4p5J0zN6wAkqadqrwIRcRdwdptFOzPzlqLMTqAG3NRvgyJiB7ADYHx8/LjW4SCwJPXWMwAy8/JuyyPi94GPApdlZrYpsh84r2V6czGvU327gF0AExMT7dbXU81bQkpST/2eBXQF8GfAxzLzrQ7F7gW2RcTWiFgOXAPc2k+9vczdD8BDQJLUUb9fkT8PrAPujIj7I+KLABGxKSJuBygGiT8F3AHsAb6RmY/0WW9X/hqoJPXW8xBQN5n5zg7zDwBXtUzfDtzeT13HwrOAJKm3Uh4ktwcgSb2VMgDm7wlsAEhSJ6UMAK8ElqTeSrmHtAcgSb2VMgDmrwMwACSpk1IGQL3RIAIqBoAkdVTKAKg10m//ktRDKQOg3kiP/0tSD6UMgGYPoJRvTZKWTCn3krV6wx6AJPVQzgBwDECSeiplADgGIEm9lTIA7AFIUm+lDIB6I6mOlfKtSdKSKeVe0h6AJPVWygCoNzwLSJJ6KWUA1OoOAktSL6UMgOYYgAEgSd2UMgBqjWTMK4ElqatS7iXrDgJLUk+lDICag8CS1FMpA8AegCT1VsoAqPlTEJLUUykDwB6AJPVWygBoXgdQyrcmSUumlHtJewCS1FspA6DWaDDmhWCS1FVJA8AegCT1Us4A8LeAJKmnUgaAYwCS1FspA6DmDWEkqadqPy+OiM8AvwlMA08Cf5CZr7Up9wzwBlAHapk50U+9vdQbDXsAktRDv1+T7wTel5kXAk8AN3Qp++HMfP+J3vmDVwJL0mL0FQCZ+Z3MrBWTPwQ299+k/jkGIEm9LeWB8j8E/qHDsgS+ExH3RcSOJayzrY9sP4v3nHPKia5Gkn6u9RwDiIi7gLPbLNqZmbcUZXYCNeCmDqu5NDP3R8SZwJ0R8Vhmfr9DfTuAHQDj4+OLeAtv99lrLjqu10nSKOkZAJl5ebflEfH7wEeByzIzO6xjf/H4YkTcDFwMtA2AzNwF7AKYmJhouz5JUv/6OgQUEVcAfwZ8LDPf6lBmTUSsm30OfAR4uJ96JUn963cM4PPAOpqHde6PiC8CRMSmiLi9KHMW8IOIeAD4EXBbZn67z3olSX3q6zqAzHxnh/kHgKuK508Bv9hPPZKkpeflspI0ogwASRpRBoAkjSgDQJJGVHQ4dX8oRMRLwLPH+fINwMElbM6JYBv7N+ztA9u4VGzj4pyfmRsXU3CoA6AfEbH7ZPzwXD9sY/+GvX1gG5eKbVx6HgKSpBFlAEjSiCpzAOwadAMWwTb2b9jbB7ZxqdjGJVbaMQBJUndl7gFIkrooXQBExBUR8XhE7I2I6wfdHoCIOC8ivhcRj0bEIxHx6WL+6RFxZ0T8pHhcPwRtHYuI/xcR3yqmt0bEPcX2/HpELB9w+06LiG9GxGMRsSciLhm27RgRf1L8Oz8cEX8XESsHvR0j4m8i4sWIeLhlXtvtFk3/qWjrgxHxgQG28TPFv/WDEXFzRJzWsuyGoo2PR8RvDKJ9Lcv+NCIyIjYU0wPZhseqVAEQEWPAjcCVwHbg2ojYPthWAc2b5fxpZm4HPgT8UdGu64G7M3MbcHcxPWifBva0TP8l8FfFD/+9CnxyIK2a9zng25n5bpo/MriHIdqOEXEu8G+Aicx8HzAGXMPgt+PfAlcsmNdpu10JbCv+dgBfGGAb2953vPj8XAO8t3jNfy4+/ye7fUTEeTR/5v6nLbMHtQ2PTWaW5g+4BLijZfoG4IZBt6tNO28Bfh14HDinmHcO8PiA27WZ5o7gnwPfAoLmRS3Vdtt3AO07FXiaYuyqZf7QbEfgXOA54HSav7b7LeA3hmE7AluAh3ttN+CvgWvblTvZbVyw7OPATcXzoz7bwB3AJYNoH/BNml9GngE2DHobHstfqXoAzH/4Zu0r5g2NiNgCXATcA5yVmc8Xi35G894Jg/RZmjf4aRTTZwCvZWatmB709twKvAT8l+Iw1ZeKmwwNzXbM5t3v/gPNb4PPA4eA+xiu7Tir03Yb1s9R633Hh6KNEXE1sD8zH1iwaCja10vZAmCoRcRa4H8Af5yZr7cuy+bXhIGdkhURHwVezMz7BtWGRagCHwC+kJkXAZMsONwzBNtxPXA1zbDaBKyhzWGDYTPo7dbLIu47ftJFxGrg3wJ/Pui2HK+yBcB+4LyW6c3FvIGLiGU0d/43ZebfF7NfiIhziuXnAC8Oqn3ArwAfi4hngK/RPAz0OeC0iJi9cdCgt+c+YF9m3lNMf5NmIAzTdrwceDozX8rMGeDvaW7bYdqOszptt6H6HMX8fcd/twgqGI42voNm0D9QfG42Az+OiLOHpH09lS0A7gW2FWdcLKc5SHTrgNtERATwZWBPZv7HlkW3AtcVz6+jOTYwEJl5Q2ZuzswtNLfbdzPzd4HvAb9dFBt0G38GPBcRv1DMugx4lCHajjQP/XwoIlYX/+6zbRya7dii03a7Ffi94kyWDwGHWg4VnVTR+b7jtwLXRMSKiNhKc7D1RyezbZn5UGaemZlbis/NPuADxf+nQ7MNuxr0IMRS/9G8FeUTwJPAzkG3p2jTpTS71w8C9xd/V9E8xn438BPgLuD0Qbe1aO+vAd8qnl9A84O1F/jvwIoBt+39wO5iW/5PYP2wbUfg3wGPAQ8DXwVWDHo7An9Hc0xihuaO6pOdthvNwf8bi8/QQzTPaBpUG/fSPJY++7n5Ykv5nUUbHweuHET7Fix/hvlB4IFsw2P980pgSRpRZTsEJElaJANAkkaUASBJI8oAkKQRZQBI0ogyACRpRBkAkjSiDABJGlH/H2wGI3KfkVL4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "\n",
    "W = np.array([0.5, 0.5])\n",
    "b = 4.21\n",
    "n_iters = 150\n",
    "for ix in range(n_iters):\n",
    "    ## Complete the interpretation method here\n",
    "    ## 1. Initialise w, b\n",
    "    ## 2. Run Optimizer in loss\n",
    "    ## 3. Log accuracy and loss\n",
    "    ## 4. Plot the curves\n",
    "    err, W, b = stochastic_optimizer(X_train, W, y_train, b, learning_rate=0.01)\n",
    "    loss.append(err)\n",
    "print(W)\n",
    "\n",
    "plt.plot(loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942857142857143"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_model.add(Dense(units=512 , activation= 'relu',input_dim=2))\n",
    "lgs_model.add(Dense(units=256 , activation = 'relu'))\n",
    "lgs_model.add(Dense(units=128 , activation = 'relu'))\n",
    "lgs_model.add(Dense(units=16 , activation='relu'))\n",
    "lgs_model.add(Dense(units=1 , activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgs_model.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "650/650 [==============================] - 0s 143us/step - loss: 0.5093 - acc: 0.7815\n",
      "Epoch 2/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.4380 - acc: 0.8077\n",
      "Epoch 3/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.3912 - acc: 0.8385\n",
      "Epoch 4/300\n",
      "650/650 [==============================] - 0s 118us/step - loss: 0.3507 - acc: 0.8831\n",
      "Epoch 5/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.3116 - acc: 0.9292\n",
      "Epoch 6/300\n",
      "650/650 [==============================] - 0s 106us/step - loss: 0.2767 - acc: 0.9585\n",
      "Epoch 7/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.2460 - acc: 0.9646\n",
      "Epoch 8/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.2201 - acc: 0.9800\n",
      "Epoch 9/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.1968 - acc: 0.9831\n",
      "Epoch 10/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.1769 - acc: 0.9862\n",
      "Epoch 11/300\n",
      "650/650 [==============================] - 0s 113us/step - loss: 0.1586 - acc: 0.9877\n",
      "Epoch 12/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.1434 - acc: 0.9877\n",
      "Epoch 13/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.1291 - acc: 0.9892\n",
      "Epoch 14/300\n",
      "650/650 [==============================] - 0s 108us/step - loss: 0.1173 - acc: 0.9923\n",
      "Epoch 15/300\n",
      "650/650 [==============================] - 0s 121us/step - loss: 0.1067 - acc: 0.9923\n",
      "Epoch 16/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0979 - acc: 0.9908\n",
      "Epoch 17/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0893 - acc: 0.9923\n",
      "Epoch 18/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.0820 - acc: 0.9923\n",
      "Epoch 19/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0761 - acc: 0.9908\n",
      "Epoch 20/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0706 - acc: 0.9908\n",
      "Epoch 21/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.0657 - acc: 0.9923\n",
      "Epoch 22/300\n",
      "650/650 [==============================] - 0s 95us/step - loss: 0.0614 - acc: 0.9954\n",
      "Epoch 23/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0578 - acc: 0.9938\n",
      "Epoch 24/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0539 - acc: 0.9954\n",
      "Epoch 25/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0507 - acc: 0.9938\n",
      "Epoch 26/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0478 - acc: 0.9938\n",
      "Epoch 27/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0452 - acc: 0.9954\n",
      "Epoch 28/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0430 - acc: 0.9938\n",
      "Epoch 29/300\n",
      "650/650 [==============================] - 0s 121us/step - loss: 0.0407 - acc: 0.9954\n",
      "Epoch 30/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0389 - acc: 0.9954\n",
      "Epoch 31/300\n",
      "650/650 [==============================] - 0s 106us/step - loss: 0.0368 - acc: 0.9938\n",
      "Epoch 32/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0354 - acc: 0.9938\n",
      "Epoch 33/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.0337 - acc: 0.9954\n",
      "Epoch 34/300\n",
      "650/650 [==============================] - 0s 117us/step - loss: 0.0327 - acc: 0.9954\n",
      "Epoch 35/300\n",
      "650/650 [==============================] - 0s 112us/step - loss: 0.0314 - acc: 0.9954\n",
      "Epoch 36/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0300 - acc: 0.9954\n",
      "Epoch 37/300\n",
      "650/650 [==============================] - 0s 112us/step - loss: 0.0292 - acc: 0.9954\n",
      "Epoch 38/300\n",
      "650/650 [==============================] - 0s 121us/step - loss: 0.0280 - acc: 0.9954\n",
      "Epoch 39/300\n",
      "650/650 [==============================] - 0s 148us/step - loss: 0.0271 - acc: 0.9969\n",
      "Epoch 40/300\n",
      "650/650 [==============================] - 0s 169us/step - loss: 0.0262 - acc: 0.9954\n",
      "Epoch 41/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0254 - acc: 0.9969\n",
      "Epoch 42/300\n",
      "650/650 [==============================] - 0s 143us/step - loss: 0.0247 - acc: 0.9954\n",
      "Epoch 43/300\n",
      "650/650 [==============================] - 0s 141us/step - loss: 0.0241 - acc: 0.9954\n",
      "Epoch 44/300\n",
      "650/650 [==============================] - 0s 151us/step - loss: 0.0233 - acc: 0.9969\n",
      "Epoch 45/300\n",
      "650/650 [==============================] - 0s 139us/step - loss: 0.0229 - acc: 0.9954\n",
      "Epoch 46/300\n",
      "650/650 [==============================] - 0s 112us/step - loss: 0.0219 - acc: 0.9969\n",
      "Epoch 47/300\n",
      "650/650 [==============================] - 0s 121us/step - loss: 0.0211 - acc: 0.9954\n",
      "Epoch 48/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.0209 - acc: 0.9969\n",
      "Epoch 49/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0206 - acc: 0.9954\n",
      "Epoch 50/300\n",
      "650/650 [==============================] - 0s 118us/step - loss: 0.0204 - acc: 0.9954\n",
      "Epoch 51/300\n",
      "650/650 [==============================] - 0s 122us/step - loss: 0.0199 - acc: 0.9954\n",
      "Epoch 52/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0194 - acc: 0.9954\n",
      "Epoch 53/300\n",
      "650/650 [==============================] - 0s 127us/step - loss: 0.0189 - acc: 0.9954\n",
      "Epoch 54/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0184 - acc: 0.9969\n",
      "Epoch 55/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0181 - acc: 0.9969\n",
      "Epoch 56/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0180 - acc: 0.9954\n",
      "Epoch 57/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0175 - acc: 0.9954\n",
      "Epoch 58/300\n",
      "650/650 [==============================] - 0s 122us/step - loss: 0.0173 - acc: 0.9954\n",
      "Epoch 59/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0171 - acc: 0.9969\n",
      "Epoch 60/300\n",
      "650/650 [==============================] - 0s 94us/step - loss: 0.0166 - acc: 0.9969\n",
      "Epoch 61/300\n",
      "650/650 [==============================] - 0s 113us/step - loss: 0.0163 - acc: 0.9969\n",
      "Epoch 62/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0163 - acc: 0.9954\n",
      "Epoch 63/300\n",
      "650/650 [==============================] - 0s 117us/step - loss: 0.0157 - acc: 0.9969\n",
      "Epoch 64/300\n",
      "650/650 [==============================] - 0s 122us/step - loss: 0.0157 - acc: 0.9969\n",
      "Epoch 65/300\n",
      "650/650 [==============================] - 0s 129us/step - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 66/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 67/300\n",
      "650/650 [==============================] - 0s 127us/step - loss: 0.0150 - acc: 0.9969\n",
      "Epoch 68/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0147 - acc: 0.9985\n",
      "Epoch 69/300\n",
      "650/650 [==============================] - 0s 108us/step - loss: 0.0144 - acc: 0.9969\n",
      "Epoch 70/300\n",
      "650/650 [==============================] - 0s 134us/step - loss: 0.0144 - acc: 0.9954\n",
      "Epoch 71/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0143 - acc: 0.9969\n",
      "Epoch 72/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0142 - acc: 0.9954\n",
      "Epoch 73/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0137 - acc: 0.9969\n",
      "Epoch 74/300\n",
      "650/650 [==============================] - 0s 153us/step - loss: 0.0137 - acc: 0.9969\n",
      "Epoch 75/300\n",
      "650/650 [==============================] - 0s 145us/step - loss: 0.0133 - acc: 0.9969\n",
      "Epoch 76/300\n",
      "650/650 [==============================] - 0s 141us/step - loss: 0.0134 - acc: 0.9969\n",
      "Epoch 77/300\n",
      "650/650 [==============================] - 0s 144us/step - loss: 0.0131 - acc: 0.9969\n",
      "Epoch 78/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0132 - acc: 0.9969\n",
      "Epoch 79/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 80/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0126 - acc: 0.9985\n",
      "Epoch 81/300\n",
      "650/650 [==============================] - 0s 154us/step - loss: 0.0130 - acc: 0.9969\n",
      "Epoch 82/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0126 - acc: 0.9954\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 132us/step - loss: 0.0124 - acc: 0.9969\n",
      "Epoch 84/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0125 - acc: 0.9969\n",
      "Epoch 85/300\n",
      "650/650 [==============================] - 0s 142us/step - loss: 0.0121 - acc: 0.9969\n",
      "Epoch 86/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.0122 - acc: 0.9969\n",
      "Epoch 87/300\n",
      "650/650 [==============================] - 0s 95us/step - loss: 0.0116 - acc: 0.9985\n",
      "Epoch 88/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0116 - acc: 0.9969\n",
      "Epoch 89/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 90/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0115 - acc: 0.9969\n",
      "Epoch 91/300\n",
      "650/650 [==============================] - 0s 93us/step - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 92/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 93/300\n",
      "650/650 [==============================] - 0s 136us/step - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 94/300\n",
      "650/650 [==============================] - 0s 139us/step - loss: 0.0113 - acc: 0.9985\n",
      "Epoch 95/300\n",
      "650/650 [==============================] - 0s 145us/step - loss: 0.0112 - acc: 0.9954\n",
      "Epoch 96/300\n",
      "650/650 [==============================] - 0s 146us/step - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 97/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0110 - acc: 0.9985\n",
      "Epoch 98/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0111 - acc: 0.9985\n",
      "Epoch 99/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0118 - acc: 0.9985\n",
      "Epoch 100/300\n",
      "650/650 [==============================] - 0s 95us/step - loss: 0.0110 - acc: 0.9969\n",
      "Epoch 101/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0106 - acc: 0.9985\n",
      "Epoch 102/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 103/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0106 - acc: 0.9969\n",
      "Epoch 104/300\n",
      "650/650 [==============================] - 0s 138us/step - loss: 0.0107 - acc: 0.9969\n",
      "Epoch 105/300\n",
      "650/650 [==============================] - 0s 139us/step - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 106/300\n",
      "650/650 [==============================] - 0s 135us/step - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 107/300\n",
      "650/650 [==============================] - 0s 134us/step - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 108/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0100 - acc: 0.9985\n",
      "Epoch 109/300\n",
      "650/650 [==============================] - 0s 95us/step - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 110/300\n",
      "650/650 [==============================] - 0s 146us/step - loss: 0.0109 - acc: 0.9985\n",
      "Epoch 111/300\n",
      "650/650 [==============================] - 0s 139us/step - loss: 0.0098 - acc: 0.9985\n",
      "Epoch 112/300\n",
      "650/650 [==============================] - 0s 159us/step - loss: 0.0099 - acc: 0.9985\n",
      "Epoch 113/300\n",
      "650/650 [==============================] - 0s 129us/step - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 114/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 115/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.0097 - acc: 0.9985\n",
      "Epoch 116/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 117/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0099 - acc: 0.9969\n",
      "Epoch 118/300\n",
      "650/650 [==============================] - 0s 118us/step - loss: 0.0102 - acc: 0.9969\n",
      "Epoch 119/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 120/300\n",
      "650/650 [==============================] - 0s 166us/step - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 121/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 122/300\n",
      "650/650 [==============================] - 0s 94us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 123/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 124/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 125/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0095 - acc: 0.9985\n",
      "Epoch 126/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0093 - acc: 0.9969\n",
      "Epoch 127/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 128/300\n",
      "650/650 [==============================] - 0s 128us/step - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 129/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 130/300\n",
      "650/650 [==============================] - 0s 141us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 131/300\n",
      "650/650 [==============================] - 0s 139us/step - loss: 0.0091 - acc: 0.9969\n",
      "Epoch 132/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0093 - acc: 0.9985\n",
      "Epoch 133/300\n",
      "650/650 [==============================] - 0s 128us/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 134/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0090 - acc: 0.9985\n",
      "Epoch 135/300\n",
      "650/650 [==============================] - 0s 106us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 136/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.0092 - acc: 0.9969\n",
      "Epoch 137/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 138/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 139/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 140/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.0086 - acc: 0.9985\n",
      "Epoch 141/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 142/300\n",
      "650/650 [==============================] - 0s 112us/step - loss: 0.0090 - acc: 0.9969\n",
      "Epoch 143/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0088 - acc: 0.9985\n",
      "Epoch 144/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 145/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0087 - acc: 0.9969\n",
      "Epoch 146/300\n",
      "650/650 [==============================] - 0s 106us/step - loss: 0.0087 - acc: 0.9969\n",
      "Epoch 147/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 148/300\n",
      "650/650 [==============================] - 0s 120us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 149/300\n",
      "650/650 [==============================] - 0s 125us/step - loss: 0.0087 - acc: 0.9969\n",
      "Epoch 150/300\n",
      "650/650 [==============================] - 0s 122us/step - loss: 0.0086 - acc: 0.9969\n",
      "Epoch 151/300\n",
      "650/650 [==============================] - 0s 108us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 152/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0087 - acc: 0.9985\n",
      "Epoch 153/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0084 - acc: 0.9985\n",
      "Epoch 154/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0111 - acc: 0.9969\n",
      "Epoch 155/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0088 - acc: 0.9969\n",
      "Epoch 156/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 157/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0087 - acc: 0.9969\n",
      "Epoch 158/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 159/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 160/300\n",
      "650/650 [==============================] - 0s 106us/step - loss: 0.0085 - acc: 0.9985\n",
      "Epoch 161/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.0083 - acc: 0.9985\n",
      "Epoch 162/300\n",
      "650/650 [==============================] - 0s 122us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 163/300\n",
      "650/650 [==============================] - 0s 118us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 164/300\n",
      "650/650 [==============================] - 0s 117us/step - loss: 0.0082 - acc: 0.9985\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 121us/step - loss: 0.0084 - acc: 0.9969\n",
      "Epoch 166/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 167/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 168/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0085 - acc: 0.9969\n",
      "Epoch 169/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 170/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0082 - acc: 0.9985\n",
      "Epoch 171/300\n",
      "650/650 [==============================] - 0s 89us/step - loss: 0.0078 - acc: 0.9985\n",
      "Epoch 172/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 173/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 174/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0083 - acc: 0.9969\n",
      "Epoch 175/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0081 - acc: 0.9985\n",
      "Epoch 176/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0079 - acc: 0.9985\n",
      "Epoch 177/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 178/300\n",
      "650/650 [==============================] - 0s 91us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 179/300\n",
      "650/650 [==============================] - 0s 91us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 180/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 181/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 182/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 183/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0076 - acc: 0.9985\n",
      "Epoch 184/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 185/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 186/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 187/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0080 - acc: 0.9969\n",
      "Epoch 188/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 189/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 190/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0081 - acc: 0.9969\n",
      "Epoch 191/300\n",
      "650/650 [==============================] - 0s 88us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 192/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0073 - acc: 0.9985\n",
      "Epoch 193/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 194/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0076 - acc: 0.9969\n",
      "Epoch 195/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 196/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 197/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 198/300\n",
      "650/650 [==============================] - 0s 95us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 199/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 200/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 201/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0077 - acc: 0.9985\n",
      "Epoch 202/300\n",
      "650/650 [==============================] - 0s 115us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 203/300\n",
      "650/650 [==============================] - 0s 97us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 204/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0076 - acc: 0.9969\n",
      "Epoch 205/300\n",
      "650/650 [==============================] - 0s 98us/step - loss: 0.0073 - acc: 0.9985\n",
      "Epoch 206/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 207/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0077 - acc: 0.9985\n",
      "Epoch 208/300\n",
      "650/650 [==============================] - 0s 104us/step - loss: 0.0080 - acc: 0.9969\n",
      "Epoch 209/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0076 - acc: 0.9969\n",
      "Epoch 210/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 211/300\n",
      "650/650 [==============================] - 0s 127us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 212/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 213/300\n",
      "650/650 [==============================] - 0s 156us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 214/300\n",
      "650/650 [==============================] - 0s 158us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 215/300\n",
      "650/650 [==============================] - 0s 125us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 216/300\n",
      "650/650 [==============================] - 0s 94us/step - loss: 0.0070 - acc: 0.9969\n",
      "Epoch 217/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 218/300\n",
      "650/650 [==============================] - 0s 113us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 219/300\n",
      "650/650 [==============================] - 0s 142us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 220/300\n",
      "650/650 [==============================] - 0s 138us/step - loss: 0.0077 - acc: 0.9985\n",
      "Epoch 221/300\n",
      "650/650 [==============================] - 0s 130us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 222/300\n",
      "650/650 [==============================] - 0s 135us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 223/300\n",
      "650/650 [==============================] - 0s 90us/step - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 224/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0080 - acc: 0.9969\n",
      "Epoch 225/300\n",
      "650/650 [==============================] - 0s 126us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 226/300\n",
      "650/650 [==============================] - 0s 138us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 227/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 228/300\n",
      "650/650 [==============================] - 0s 144us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 229/300\n",
      "650/650 [==============================] - 0s 152us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 230/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 231/300\n",
      "650/650 [==============================] - 0s 130us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 232/300\n",
      "650/650 [==============================] - 0s 146us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 233/300\n",
      "650/650 [==============================] - 0s 135us/step - loss: 0.0078 - acc: 0.9969\n",
      "Epoch 234/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 235/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0074 - acc: 0.9985\n",
      "Epoch 236/300\n",
      "650/650 [==============================] - 0s 127us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 237/300\n",
      "650/650 [==============================] - 0s 110us/step - loss: 0.0073 - acc: 0.9985\n",
      "Epoch 238/300\n",
      "650/650 [==============================] - 0s 164us/step - loss: 0.0070 - acc: 0.9969\n",
      "Epoch 239/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0068 - acc: 0.9985\n",
      "Epoch 240/300\n",
      "650/650 [==============================] - 0s 121us/step - loss: 0.0067 - acc: 0.9985\n",
      "Epoch 241/300\n",
      "650/650 [==============================] - 0s 129us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 242/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 243/300\n",
      "650/650 [==============================] - 0s 149us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 244/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0096 - acc: 0.9969\n",
      "Epoch 245/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0068 - acc: 0.9985\n",
      "Epoch 246/300\n",
      "650/650 [==============================] - 0s 132us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 247/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650/650 [==============================] - 0s 125us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 248/300\n",
      "650/650 [==============================] - 0s 146us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 249/300\n",
      "650/650 [==============================] - 0s 135us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 250/300\n",
      "650/650 [==============================] - 0s 133us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 251/300\n",
      "650/650 [==============================] - 0s 124us/step - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 252/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 253/300\n",
      "650/650 [==============================] - 0s 91us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 254/300\n",
      "650/650 [==============================] - 0s 90us/step - loss: 0.0065 - acc: 0.9969\n",
      "Epoch 255/300\n",
      "650/650 [==============================] - 0s 89us/step - loss: 0.0067 - acc: 0.9969\n",
      "Epoch 256/300\n",
      "650/650 [==============================] - 0s 157us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 257/300\n",
      "650/650 [==============================] - 0s 145us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 258/300\n",
      "650/650 [==============================] - 0s 132us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 259/300\n",
      "650/650 [==============================] - 0s 138us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 260/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 261/300\n",
      "650/650 [==============================] - 0s 92us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 262/300\n",
      "650/650 [==============================] - 0s 111us/step - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 263/300\n",
      "650/650 [==============================] - 0s 94us/step - loss: 0.0065 - acc: 0.9969\n",
      "Epoch 264/300\n",
      "650/650 [==============================] - 0s 102us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 265/300\n",
      "650/650 [==============================] - 0s 137us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 266/300\n",
      "650/650 [==============================] - 0s 151us/step - loss: 0.0066 - acc: 0.9985\n",
      "Epoch 267/300\n",
      "650/650 [==============================] - 0s 142us/step - loss: 0.0073 - acc: 0.9969\n",
      "Epoch 268/300\n",
      "650/650 [==============================] - 0s 137us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 269/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 270/300\n",
      "650/650 [==============================] - 0s 129us/step - loss: 0.0073 - acc: 0.9985\n",
      "Epoch 271/300\n",
      "650/650 [==============================] - 0s 109us/step - loss: 0.0074 - acc: 0.9969\n",
      "Epoch 272/300\n",
      "650/650 [==============================] - 0s 94us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 273/300\n",
      "650/650 [==============================] - 0s 103us/step - loss: 0.0071 - acc: 0.9985\n",
      "Epoch 274/300\n",
      "650/650 [==============================] - 0s 114us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 275/300\n",
      "650/650 [==============================] - 0s 137us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 276/300\n",
      "650/650 [==============================] - 0s 149us/step - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 277/300\n",
      "650/650 [==============================] - 0s 132us/step - loss: 0.0076 - acc: 0.9969\n",
      "Epoch 278/300\n",
      "650/650 [==============================] - 0s 99us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 279/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0085 - acc: 0.9969\n",
      "Epoch 280/300\n",
      "650/650 [==============================] - 0s 117us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 281/300\n",
      "650/650 [==============================] - 0s 107us/step - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 282/300\n",
      "650/650 [==============================] - 0s 100us/step - loss: 0.0098 - acc: 0.9954\n",
      "Epoch 283/300\n",
      "650/650 [==============================] - 0s 116us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 284/300\n",
      "650/650 [==============================] - 0s 131us/step - loss: 0.0070 - acc: 0.9969\n",
      "Epoch 285/300\n",
      "650/650 [==============================] - 0s 129us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 286/300\n",
      "650/650 [==============================] - 0s 164us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 287/300\n",
      "650/650 [==============================] - 0s 137us/step - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 288/300\n",
      "650/650 [==============================] - 0s 119us/step - loss: 0.0071 - acc: 0.9969\n",
      "Epoch 289/300\n",
      "650/650 [==============================] - 0s 105us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 290/300\n",
      "650/650 [==============================] - 0s 126us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 291/300\n",
      "650/650 [==============================] - 0s 113us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 292/300\n",
      "650/650 [==============================] - 0s 96us/step - loss: 0.0068 - acc: 0.9969\n",
      "Epoch 293/300\n",
      "650/650 [==============================] - 0s 143us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 294/300\n",
      "650/650 [==============================] - 0s 150us/step - loss: 0.0072 - acc: 0.9969\n",
      "Epoch 295/300\n",
      "650/650 [==============================] - 0s 127us/step - loss: 0.0067 - acc: 0.9969\n",
      "Epoch 296/300\n",
      "650/650 [==============================] - 0s 149us/step - loss: 0.0070 - acc: 0.9969\n",
      "Epoch 297/300\n",
      "650/650 [==============================] - 0s 141us/step - loss: 0.0069 - acc: 0.9969\n",
      "Epoch 298/300\n",
      "650/650 [==============================] - 0s 101us/step - loss: 0.0062 - acc: 0.9969\n",
      "Epoch 299/300\n",
      "650/650 [==============================] - 0s 112us/step - loss: 0.0065 - acc: 0.9985\n",
      "Epoch 300/300\n",
      "650/650 [==============================] - 0s 147us/step - loss: 0.0066 - acc: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c01f53710>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgs_model.fit(X_train,y_train,epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 0s 69us/step\n",
      "[0.01723050335156066, 0.9942857142857143]\n"
     ]
    }
   ],
   "source": [
    "loss=lgs_model.evaluate(X_test,y_test)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49404266e-04]\n",
      " [4.21768840e-04]\n",
      " [9.99963880e-01]\n",
      " [2.74285965e-04]\n",
      " [2.10598926e-04]\n",
      " [2.07611520e-04]\n",
      " [9.99927878e-01]\n",
      " [9.99999166e-01]\n",
      " [1.52643042e-05]\n",
      " [9.99966979e-01]\n",
      " [9.99202073e-01]\n",
      " [1.13318965e-04]\n",
      " [2.73445094e-05]\n",
      " [9.99999881e-01]\n",
      " [9.99923229e-01]\n",
      " [1.01237329e-05]\n",
      " [9.89222972e-05]\n",
      " [7.86749661e-01]\n",
      " [9.94247317e-01]\n",
      " [1.05492650e-02]\n",
      " [1.91269297e-04]\n",
      " [1.24386555e-04]\n",
      " [9.99885678e-01]\n",
      " [1.96682726e-04]\n",
      " [9.99922872e-01]\n",
      " [9.99968171e-01]\n",
      " [2.39669830e-02]\n",
      " [9.99988079e-01]\n",
      " [9.99902010e-01]\n",
      " [1.67811086e-04]\n",
      " [3.39432183e-04]\n",
      " [9.99989033e-01]\n",
      " [3.49854759e-04]\n",
      " [1.74161294e-04]\n",
      " [9.99992967e-01]\n",
      " [9.99997258e-01]\n",
      " [9.99515057e-01]\n",
      " [9.99514103e-01]\n",
      " [6.21330051e-04]\n",
      " [2.47898977e-04]\n",
      " [3.19112842e-05]\n",
      " [6.62631792e-05]\n",
      " [1.23161473e-04]\n",
      " [3.24281427e-06]\n",
      " [1.36483693e-04]\n",
      " [9.99967337e-01]\n",
      " [9.97522295e-01]\n",
      " [9.99781668e-01]\n",
      " [3.77634645e-01]\n",
      " [9.99891996e-01]\n",
      " [1.71614738e-04]\n",
      " [8.76022605e-05]\n",
      " [9.43050312e-04]\n",
      " [8.58791973e-05]\n",
      " [9.99987602e-01]\n",
      " [6.04671659e-04]\n",
      " [1.76073314e-04]\n",
      " [9.78526235e-01]\n",
      " [9.99965787e-01]\n",
      " [5.10910351e-04]\n",
      " [1.05285380e-05]\n",
      " [9.99996066e-01]\n",
      " [8.95065841e-06]\n",
      " [9.99491811e-01]\n",
      " [4.09688131e-04]\n",
      " [1.52911452e-04]\n",
      " [6.69578207e-04]\n",
      " [2.43455361e-04]\n",
      " [5.45071147e-04]\n",
      " [1.54800038e-03]\n",
      " [1.01757541e-04]\n",
      " [9.99805629e-01]\n",
      " [9.99990940e-01]\n",
      " [7.25836318e-04]\n",
      " [9.99897957e-01]\n",
      " [9.99999642e-01]\n",
      " [9.99977350e-01]\n",
      " [9.99993920e-01]\n",
      " [9.99995708e-01]\n",
      " [3.62107784e-01]\n",
      " [9.99953151e-01]\n",
      " [9.99989152e-01]\n",
      " [9.97572958e-01]\n",
      " [1.97832283e-04]\n",
      " [1.28324711e-04]\n",
      " [9.99802053e-01]\n",
      " [4.72201325e-04]\n",
      " [2.29681245e-05]\n",
      " [9.99991655e-01]\n",
      " [3.59345373e-04]\n",
      " [7.60304334e-04]\n",
      " [5.52208221e-05]\n",
      " [9.99969840e-01]\n",
      " [9.99997735e-01]\n",
      " [2.04670767e-04]\n",
      " [9.99630690e-01]\n",
      " [9.99896049e-01]\n",
      " [9.99989867e-01]\n",
      " [1.78515736e-04]\n",
      " [1.84512712e-04]\n",
      " [9.99974728e-01]\n",
      " [8.50990400e-05]\n",
      " [1.89479149e-04]\n",
      " [9.99570191e-01]\n",
      " [9.99978662e-01]\n",
      " [9.99980211e-01]\n",
      " [2.68872216e-04]\n",
      " [9.99758542e-01]\n",
      " [3.91998619e-05]\n",
      " [9.99997616e-01]\n",
      " [9.99477208e-01]\n",
      " [5.51499845e-03]\n",
      " [9.99991775e-01]\n",
      " [2.13181658e-04]\n",
      " [4.87114594e-04]\n",
      " [1.71442851e-04]\n",
      " [1.17378705e-03]\n",
      " [9.99985933e-01]\n",
      " [2.52885371e-03]\n",
      " [3.19704268e-04]\n",
      " [7.44078570e-05]\n",
      " [9.41483158e-05]\n",
      " [9.99998093e-01]\n",
      " [5.11782346e-05]\n",
      " [9.99991536e-01]\n",
      " [6.90494926e-05]\n",
      " [9.99994755e-01]\n",
      " [2.02100346e-04]\n",
      " [9.99957681e-01]\n",
      " [9.99971032e-01]\n",
      " [9.99964237e-01]\n",
      " [9.38379788e-04]\n",
      " [2.39085231e-04]\n",
      " [7.41076074e-04]\n",
      " [9.99994040e-01]\n",
      " [9.99449670e-01]\n",
      " [7.44198918e-01]\n",
      " [9.99997497e-01]\n",
      " [9.99777973e-01]\n",
      " [4.52783250e-04]\n",
      " [1.08845961e-05]\n",
      " [9.69898174e-05]\n",
      " [9.99979973e-01]\n",
      " [2.59367109e-04]\n",
      " [9.99314666e-01]\n",
      " [9.96968210e-01]\n",
      " [9.99714911e-01]\n",
      " [3.36506273e-05]\n",
      " [9.99999523e-01]\n",
      " [9.99990702e-01]\n",
      " [1.43312471e-04]\n",
      " [6.75302988e-04]\n",
      " [1.02957994e-04]\n",
      " [9.99991417e-01]\n",
      " [9.99959707e-01]\n",
      " [1.06353786e-04]\n",
      " [7.31773471e-05]\n",
      " [3.66743683e-04]\n",
      " [8.47501564e-04]\n",
      " [1.34799402e-05]\n",
      " [1.19568482e-04]\n",
      " [9.99996066e-01]\n",
      " [9.99976754e-01]\n",
      " [9.06743050e-01]\n",
      " [9.99967694e-01]\n",
      " [9.99950171e-01]\n",
      " [9.99995708e-01]\n",
      " [9.99985814e-01]\n",
      " [9.99894857e-01]\n",
      " [9.73381758e-01]\n",
      " [9.99976993e-01]\n",
      " [9.99958754e-01]\n",
      " [9.99826610e-01]\n",
      " [5.35931940e-05]\n",
      " [1.19488372e-03]\n",
      " [9.99984503e-01]\n",
      " [2.40545496e-02]\n",
      " [9.99985218e-01]\n",
      " [9.99995947e-01]\n",
      " [7.82501302e-04]\n",
      " [1.57363334e-04]\n",
      " [9.99924421e-01]\n",
      " [9.99995828e-01]\n",
      " [8.58438671e-06]\n",
      " [9.99961734e-01]\n",
      " [9.99967098e-01]\n",
      " [4.16338095e-04]\n",
      " [8.82076442e-01]\n",
      " [9.99989748e-01]\n",
      " [3.54366894e-05]\n",
      " [4.18939628e-04]\n",
      " [9.99912858e-01]\n",
      " [1.70863001e-04]\n",
      " [1.83170050e-05]\n",
      " [1.87346537e-04]\n",
      " [9.99884367e-01]\n",
      " [9.99851823e-01]\n",
      " [3.81051184e-04]\n",
      " [9.99998212e-01]\n",
      " [9.99956369e-01]\n",
      " [9.99971986e-01]\n",
      " [9.99985814e-01]\n",
      " [9.99997735e-01]\n",
      " [9.99815285e-01]\n",
      " [2.29513973e-01]\n",
      " [2.75638129e-04]\n",
      " [2.16920525e-01]\n",
      " [9.99905467e-01]\n",
      " [9.99891043e-01]\n",
      " [2.05103672e-04]\n",
      " [9.99895573e-01]\n",
      " [1.46077204e-04]\n",
      " [2.09330744e-03]\n",
      " [9.99998093e-01]\n",
      " [1.12573442e-04]\n",
      " [9.99982834e-01]\n",
      " [5.36594656e-04]\n",
      " [2.72236095e-04]\n",
      " [2.46361538e-04]\n",
      " [1.29791617e-04]\n",
      " [1.22623591e-04]\n",
      " [9.99988317e-01]\n",
      " [9.99908805e-01]\n",
      " [3.06045462e-04]\n",
      " [3.30278330e-04]\n",
      " [3.66813874e-05]\n",
      " [9.99994516e-01]\n",
      " [9.97515798e-01]\n",
      " [1.55398477e-04]\n",
      " [5.81154272e-05]\n",
      " [7.64178811e-04]\n",
      " [4.16461553e-05]\n",
      " [9.99681354e-01]\n",
      " [2.76032333e-05]\n",
      " [8.34685343e-04]\n",
      " [1.34232891e-04]\n",
      " [9.99759018e-01]\n",
      " [9.21836868e-02]\n",
      " [9.99931216e-01]\n",
      " [9.99835849e-01]\n",
      " [2.39624933e-04]\n",
      " [1.24661092e-04]\n",
      " [2.10631464e-04]\n",
      " [1.61387070e-04]\n",
      " [1.92419131e-04]\n",
      " [9.99965191e-01]\n",
      " [9.99993920e-01]\n",
      " [9.75170612e-01]\n",
      " [3.28638795e-04]\n",
      " [9.99993205e-01]\n",
      " [9.99817908e-01]\n",
      " [9.99992251e-01]\n",
      " [6.36331388e-05]\n",
      " [9.24941560e-04]\n",
      " [5.87288523e-04]\n",
      " [6.28011621e-05]\n",
      " [9.99987364e-01]\n",
      " [9.99021530e-01]\n",
      " [3.73687129e-04]\n",
      " [9.99991298e-01]\n",
      " [6.06817193e-05]\n",
      " [9.99992847e-01]\n",
      " [2.19535184e-04]\n",
      " [1.79812865e-04]\n",
      " [2.55521649e-04]\n",
      " [2.19796784e-04]\n",
      " [1.58391063e-04]\n",
      " [2.37056920e-05]\n",
      " [9.99487758e-01]\n",
      " [9.99999881e-01]\n",
      " [9.99999046e-01]\n",
      " [9.99994278e-01]\n",
      " [9.95780826e-01]\n",
      " [1.07118773e-04]\n",
      " [9.99945402e-01]\n",
      " [2.27389784e-04]\n",
      " [9.98873889e-01]\n",
      " [2.13775854e-03]\n",
      " [9.99864697e-01]\n",
      " [9.99998569e-01]\n",
      " [9.99997854e-01]\n",
      " [8.09336707e-05]\n",
      " [4.25251856e-05]\n",
      " [6.84089719e-06]\n",
      " [9.99879122e-01]\n",
      " [8.52081794e-05]\n",
      " [3.34661541e-04]\n",
      " [9.99981880e-01]\n",
      " [3.64096886e-05]\n",
      " [9.99997497e-01]\n",
      " [1.58201467e-04]\n",
      " [3.82821832e-04]\n",
      " [9.99992728e-01]\n",
      " [9.99917507e-01]\n",
      " [1.47601822e-04]\n",
      " [9.99986649e-01]\n",
      " [4.11508325e-03]\n",
      " [9.99982238e-01]\n",
      " [1.58189418e-04]\n",
      " [9.86729145e-01]\n",
      " [9.99999642e-01]\n",
      " [2.23237279e-04]\n",
      " [7.81693518e-01]\n",
      " [9.99914169e-01]\n",
      " [7.00579956e-02]\n",
      " [1.86343343e-04]\n",
      " [9.99862671e-01]\n",
      " [1.10668894e-04]\n",
      " [1.61627002e-04]\n",
      " [9.99938965e-01]\n",
      " [6.56001386e-04]\n",
      " [1.73814900e-04]\n",
      " [3.37067671e-04]\n",
      " [1.32567933e-04]\n",
      " [2.11989318e-05]\n",
      " [9.99967217e-01]\n",
      " [9.99997973e-01]\n",
      " [4.16363269e-04]\n",
      " [9.48850751e-01]\n",
      " [9.99911427e-01]\n",
      " [9.99914289e-01]\n",
      " [9.99769628e-01]\n",
      " [9.99484658e-01]\n",
      " [1.21539335e-04]\n",
      " [1.60695607e-04]\n",
      " [9.99605834e-01]\n",
      " [6.23622152e-04]\n",
      " [9.99941349e-01]\n",
      " [9.99954462e-01]\n",
      " [9.57806230e-01]\n",
      " [1.20760829e-04]\n",
      " [9.97951090e-01]\n",
      " [9.99995947e-01]\n",
      " [2.79862288e-04]\n",
      " [1.51212706e-04]\n",
      " [1.74881177e-04]\n",
      " [9.99933004e-01]\n",
      " [1.80750576e-04]\n",
      " [9.99992371e-01]\n",
      " [9.99998331e-01]\n",
      " [9.97329116e-01]\n",
      " [9.99998808e-01]\n",
      " [4.42027784e-04]\n",
      " [9.99988914e-01]\n",
      " [3.00029962e-04]\n",
      " [1.62342432e-04]\n",
      " [3.94405943e-05]\n",
      " [9.99933720e-01]\n",
      " [4.14510665e-04]\n",
      " [9.10818999e-05]]\n"
     ]
    }
   ],
   "source": [
    "prd=lgs_model.predict(X_test)\n",
    "print(prd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
